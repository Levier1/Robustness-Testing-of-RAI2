{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-18T04:45:53.474173Z",
     "start_time": "2024-11-18T04:45:02.681826Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from conf import settings\n",
    "from tqdm import tqdm\n",
    "\n",
    "def split_and_transform_dataset(dataset=\"TINYIMAGENET\", \n",
    "                                data_dir=\"/home/featurize/data\",\n",
    "                                intersect_proportion=0.0, \n",
    "                                transformations=None):\n",
    "    \"\"\"\n",
    "    分割数据集并对部分样本进行随机变换。\n",
    "\n",
    "    参数：\n",
    "    - dataset: 要使用的数据集名称 (\"TinyImagenet200\", \"CIFAR10\", \"CIFAR100\")\n",
    "    - intersect_proportion: 攻击者子集与受害者子集之间的交集比例 (0.0 ~ 1.0)\n",
    "    - transformations: 每种变换的比例和范围，格式为字典\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(0)  # 设置随机种子以保证结果可重复\n",
    "\n",
    "    # 加载数据集\n",
    "    full_data_path = os.path.join(settings.DATA_PATH, dataset)\n",
    "    if dataset == \"CIFAR10\":\n",
    "        trainset = torchvision.datasets.CIFAR10(root=full_data_path, train=True, download=True, transform=None)\n",
    "    elif dataset == \"CIFAR100\":\n",
    "        trainset = torchvision.datasets.CIFAR100(root=full_data_path, train=True, download=True, transform=None)\n",
    "    else:\n",
    "         trainset = torchvision.datasets.ImageFolder(os.path.join(data_dir, \"tiny-imagenet-200\", \"train\"))\n",
    "\n",
    "    # 将图像和标签加载为列表，添加进度条\n",
    "    X_list, y_list = [], []\n",
    "    for data in tqdm(trainset, desc=\"Loading dataset\"):\n",
    "        x, y = data\n",
    "        X_list.append(np.array(x))\n",
    "        y_list.append(y)\n",
    "\n",
    "    # 转换为 NumPy 数组\n",
    "    X_np = np.array(X_list)\n",
    "    y_np = np.array(y_list)\n",
    "\n",
    "    # 随机选择受害者子集和攻击者子集的索引\n",
    "    vic_num = len(trainset) // 2\n",
    "    train_idx_array = np.arange(len(trainset))\n",
    "    np.random.shuffle(train_idx_array)\n",
    "    vic_idx = train_idx_array[:vic_num]  # 受害者子集的索引\n",
    "    shift = int(intersect_proportion * vic_num)\n",
    "    start_att_idx = vic_num - shift\n",
    "    att_idx = train_idx_array[start_att_idx: start_att_idx + vic_num]  # 攻击者子集的索引\n",
    "\n",
    "    # 构建受害者和攻击者子集\n",
    "    X_set1, y_set1 = X_np[vic_idx], y_np[vic_idx]\n",
    "    X_set2, y_set2 = X_np[att_idx], y_np[att_idx]\n",
    "\n",
    "    # 确保每种变换的存储文件夹存在\n",
    "    base_path = \"/home/featurize/work/RAI2project/RAI2data\"\n",
    "    for transform_name in transformations.keys():\n",
    "        os.makedirs(os.path.join(base_path, transform_name), exist_ok=True)\n",
    "\n",
    "    # 当 intersect_proportion == 0.0 时，保存未变换的数据集到每个变换对应的文件夹\n",
    "    if intersect_proportion == 0.0:\n",
    "        print(\"No transformations applied as intersect_proportion is set to 0.0\")\n",
    "        \n",
    "        output_filename = f\"{dataset}_intersect_{intersect_proportion}.pkl\"\n",
    "        for transform_name in transformations.keys():\n",
    "            output_path = os.path.join(base_path, transform_name, output_filename)\n",
    "            with open(output_path, \"wb\") as f:\n",
    "                pickle.dump(((X_set1, y_set1), (X_set2, y_set2)), f)\n",
    "            print(f\"Dataset saved without transformations to {output_path}\")\n",
    "        \n",
    "        return\n",
    "\n",
    "    total_samples = len(att_idx[:shift])  # 交集中样本的数量\n",
    "    print(f\"Total selected samples from attackers: {total_samples}\")\n",
    "\n",
    "    # 针对每种变换创建一个新的攻击者子集副本\n",
    "    for transform_name, (proportion, transform_params) in transformations.items():\n",
    "        num_to_transform = int(total_samples * proportion)\n",
    "        transform_indices = np.random.choice(att_idx[:shift], size=num_to_transform, replace=False)\n",
    "\n",
    "        # 创建仅应用当前变换的攻击者子集副本\n",
    "        transformed_X_set2 = X_set2.copy()\n",
    "        transformed_y_set2 = y_set2.copy()\n",
    "\n",
    "        # 输出变换操作的样本数量\n",
    "        print(f\"{transform_name.capitalize()} will transform {num_to_transform} samples.\")\n",
    "\n",
    "        # 定义每种变换操作\n",
    "        if transform_name == \"gaussian_noise\":\n",
    "            noise_std = transform_params  # 高斯噪声强度\n",
    "            transform = lambda img: img + torch.randn_like(img) * noise_std\n",
    "        elif transform_name == \"brightness\":\n",
    "            brightness_factor = transform_params  # 亮度调整因子\n",
    "            transform = transforms.ColorJitter(brightness=brightness_factor)\n",
    "        elif transform_name == \"shear\":\n",
    "            shear_range = transform_params  # 剪切范围\n",
    "            transform = transforms.RandomAffine(degrees=0, shear=shear_range)\n",
    "        elif transform_name == \"translate\":\n",
    "            translate_range = transform_params  # 平移范围\n",
    "            transform = transforms.RandomAffine(degrees=0, translate=translate_range)\n",
    "        elif transform_name == \"rotation\":\n",
    "            rotation_range = transform_params  # 旋转角度范围\n",
    "            transform = transforms.RandomRotation(degrees=rotation_range)\n",
    "\n",
    "        # 对选择的样本进行变换，并添加进度条\n",
    "        for idx in tqdm(transform_indices, desc=f\"Processing {transform_name}\"):\n",
    "            original_index = np.where(att_idx == idx)[0][0]\n",
    "            img = Image.fromarray(X_set2[original_index])  # 从攻击者子集中提取图像\n",
    "            if transform_name == \"gaussian_noise\":\n",
    "                img = transform(torch.tensor(np.array(img)).float() / 255.0)  # 将图像标准化到[0, 1]\n",
    "                img = (img * 255).clamp(0, 255).byte().numpy()  # 反归一化\n",
    "            else:\n",
    "                img = transform(img)\n",
    "            transformed_X_set2[original_index] = np.array(img)  # 用变换后的图像替换原始图像\n",
    "\n",
    "        # 保存当前变换后的受害者子集和攻击者子集到对应的文件夹\n",
    "        output_filename = f\"{dataset}_intersect_{intersect_proportion}.pkl\"\n",
    "        output_path = os.path.join(base_path, transform_name, output_filename)\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            pickle.dump(((X_set1, y_set1), (transformed_X_set2, transformed_y_set2)), f)\n",
    "\n",
    "        print(f\"Transformed dataset saved to {output_path} for transformation: {transform_name}\")\n",
    "\n",
    "# 示例调用，添加了旋转变换\n",
    "transformations = {\n",
    "    \"gaussian_noise\": (1.0, 0.1),      # 100%样本加高斯噪声，标准差0.1\n",
    "    \"brightness\": (1.0, 0.2),          # 100%样本亮度调整，因子0.2\n",
    "    \"shear\": (1.0, (15, 15)),          # 100%样本剪切，范围±15°\n",
    "    \"translate\": (1.0, (0.25, 0.25)),    # 100%样本平移，水平和垂直方向最大平移20%\n",
    "    \"rotation\": (1.0, (-25, 25)),        # 100%样本旋转，范围±25°\n",
    "}\n",
    "\n",
    "\n",
    "split_and_transform_dataset(dataset=\"TINYIMAGENET\", \n",
    "                            intersect_proportion=1.0, \n",
    "                            transformations=transformations)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 100000/100000 [00:11<00:00, 8631.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total selected samples from attackers: 50000\n",
      "Gaussian_noise will transform 50000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing gaussian_noise: 100%|██████████| 50000/50000 [00:07<00:00, 6723.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed dataset saved to /home/featurize/work/RAI2project/RAI2data/gaussian_noise/TINYIMAGENET_intersect_1.0.pkl for transformation: gaussian_noise\n",
      "Brightness will transform 50000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing brightness: 100%|██████████| 50000/50000 [00:06<00:00, 7636.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed dataset saved to /home/featurize/work/RAI2project/RAI2data/brightness/TINYIMAGENET_intersect_1.0.pkl for transformation: brightness\n",
      "Shear will transform 50000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing shear: 100%|██████████| 50000/50000 [00:04<00:00, 10362.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed dataset saved to /home/featurize/work/RAI2project/RAI2data/shear/TINYIMAGENET_intersect_1.0.pkl for transformation: shear\n",
      "Translate will transform 50000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing translate: 100%|██████████| 50000/50000 [00:04<00:00, 10333.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed dataset saved to /home/featurize/work/RAI2project/RAI2data/translate/TINYIMAGENET_intersect_1.0.pkl for transformation: translate\n",
      "Rotation will transform 50000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rotation: 100%|██████████| 50000/50000 [00:04<00:00, 12397.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed dataset saved to /home/featurize/work/RAI2project/RAI2data/rotation/TINYIMAGENET_intersect_1.0.pkl for transformation: rotation\n"
     ]
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
